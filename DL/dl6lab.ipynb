{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wusm5KD8TBQR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5JkJF_4TMVS"
   },
   "outputs": [],
   "source": [
    "def load_data_svhn(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.SVHN(\n",
    "        root=\"../data\", split='train', transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.SVHN(\n",
    "        root=\"../data\", split='test', transform=trans, download=True)\n",
    "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [43257, 30000],\n",
    "                                                           generator=torch.Generator().manual_seed(42))\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_val, batch_size, shuffle=False,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIljR19NVAoo"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, data_iter, loss, device):\n",
    "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    total_loss = 0\n",
    "    total_hits = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            total_loss += float(l)\n",
    "            total_hits += sum(net(X).argmax(axis=1).type(y.dtype) == y)\n",
    "            total_samples += y.numel()\n",
    "    return float(total_loss) / len(data_iter), float(total_hits) / total_samples  * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAvWiilyVCZ0"
   },
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss, optimizer, device):  \n",
    "    # Set the model to training mode\n",
    "    net.train()\n",
    "    # Sum of training loss, sum of training correct predictions, no. of examples\n",
    "    total_loss = 0\n",
    "    total_hits = 0\n",
    "    total_samples = 0\n",
    "    for X, y in train_iter:\n",
    "        # Compute gradients and update parameters\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        # Using PyTorch built-in optimizer & loss criterion\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(l)\n",
    "        total_hits += sum(y_hat.argmax(axis=1).type(y.dtype) == y)\n",
    "        total_samples += y.numel()\n",
    "    # Return training loss and training accuracy\n",
    "    return float(total_loss) / len(train_iter), float(total_hits) / total_samples  * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jhtvMVnVEPR"
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, val_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model.\"\"\"\n",
    "    train_loss_all = []\n",
    "    train_acc_all = []\n",
    "    val_loss_all = []\n",
    "    val_acc_all = []\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('Training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(net, train_iter, loss, optimizer, device)\n",
    "        train_loss_all.append(train_loss)\n",
    "        train_acc_all.append(train_acc)\n",
    "        val_loss, val_acc = evaluate_accuracy(net, val_iter, loss, device)\n",
    "        val_loss_all.append(val_loss)\n",
    "        val_acc_all.append(val_acc)\n",
    "        print(f'Epoch {epoch + 1}, Train loss {train_loss:.2f}, Train accuracy {train_acc:.2f}, Validation loss {val_loss:.2f}, Validation accuracy {val_acc:.2f}')\n",
    "    test_loss, test_acc = evaluate_accuracy(net, test_iter, loss, device)\n",
    "    print(f'Test loss {test_loss:.2f}, Test accuracy {test_acc:.2f}')\n",
    "\n",
    "    return train_loss_all, train_acc_all, val_loss_all, val_acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6p5nNd6UVHBC"
   },
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_C-jFthEVJG1"
   },
   "outputs": [],
   "source": [
    "def plot_loss(train_loss_all, val_loss_all):\n",
    "    epochs = range(1, len(train_loss_all) + 1) \n",
    "    plt.plot(epochs, train_loss_all, 'bo', label='Training loss') \n",
    "    plt.plot(epochs, val_loss_all, 'b', label='Validation loss') \n",
    "    plt.title('Training and validation loss') \n",
    "    plt.xlabel('Epochs') \n",
    "    plt.ylabel('Loss') \n",
    "    plt.legend()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwoeBGkFVKen"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(train_acc_all, val_acc_all):\n",
    "    epochs = range(1, len(train_acc_all) + 1)\n",
    "    plt.plot(epochs, train_acc_all, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc_all, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs') \n",
    "    plt.ylabel('Accuracy') \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IJQIDhdVLpk"
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = nn.ReLU()(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return nn.ReLU()(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXcvbMe1Vi1Y"
   },
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuGyxdNjVpVh"
   },
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XB7CwHWVqoD"
   },
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWAYhSR2Vr9q"
   },
   "outputs": [],
   "source": [
    "rsnet = nn.Sequential(b1, b2, b3, \n",
    "                    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                    nn.Flatten(), nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSczK6zVVuo8",
    "outputId": "a59417bc-2804-4b84-9467-504a93e0bc21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Training on cuda:0\n",
      "Epoch 1, Train loss 2.44, Train accuracy 18.45, Validation loss 2.24, Validation accuracy 19.50\n",
      "Epoch 2, Train loss 2.22, Train accuracy 20.69, Validation loss 2.19, Validation accuracy 23.50\n",
      "Epoch 3, Train loss 1.76, Train accuracy 39.86, Validation loss 1.46, Validation accuracy 51.23\n",
      "Epoch 4, Train loss 0.64, Train accuracy 80.42, Validation loss 0.52, Validation accuracy 83.86\n",
      "Epoch 5, Train loss 0.36, Train accuracy 88.93, Validation loss 0.65, Validation accuracy 78.67\n",
      "Epoch 6, Train loss 0.29, Train accuracy 91.49, Validation loss 0.37, Validation accuracy 88.79\n",
      "Epoch 7, Train loss 0.25, Train accuracy 92.82, Validation loss 0.30, Validation accuracy 91.18\n",
      "Epoch 8, Train loss 0.21, Train accuracy 93.77, Validation loss 0.33, Validation accuracy 90.12\n",
      "Epoch 9, Train loss 0.19, Train accuracy 94.56, Validation loss 0.42, Validation accuracy 87.19\n",
      "Epoch 10, Train loss 0.17, Train accuracy 95.11, Validation loss 0.42, Validation accuracy 87.10\n",
      "Test loss 0.42, Test accuracy 87.12\n"
     ]
    }
   ],
   "source": [
    "batch_size, lr, num_epochs = 256, 0.9, 10\n",
    "train_iter, val_iter, test_iter = load_data_svhn(batch_size, resize=96)\n",
    "train_loss_all, train_acc_all, val_loss_all, val_acc_all = train(rsnet, train_iter, val_iter, test_iter, num_epochs, lr, try_gpu()) #11 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN6ZHJb7bM9Z"
   },
   "outputs": [],
   "source": [
    "def c_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    c1=nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "    layers.append(c1)\n",
    "    layers.append(nn.ReLU())\n",
    "    in_channels = out_channels\n",
    "    c2=nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "    layers.append(c2)\n",
    "    layers.append(nn.BatchNorm())\n",
    "    c3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=1)\n",
    "    layers.append(nn.Add(c2,c3))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCSofSKTV9Z6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
